{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second part, we will create and train a MultiLayer Perceptron (MLP) and a Convolutional Neural Network (CNN) on the benchmark dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a common dataset, MNIST can be found in the datasets module of keras (actually, it's only on tensorflow in some versions, so try to remove the `tf` part in the string below and see if it works for you)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train_images, mnist_train_labels), (mnist_validation_images, mnist_validation_labels) = tf.keras.datasets.mnist.load_data()\n",
    "mnist_train_images.shape, mnist_train_labels.shape, mnist_validation_images.shape, mnist_validation_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what does this variable assignment mean?\n",
    "\n",
    "```python\n",
    "(mnist_train_images, mnist_train_labels), (mnist_validation_images, mnist_validation_labels) = ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with querying the dataset first...\n",
    "\n",
    "We use matplotlib for plotting the image here for two reasons:\n",
    "\n",
    "1. We can add a title to the data (e.g., by adding the label)\n",
    "2. PIL shows images on a 1:1 scale, thus a 28 x 28 image is too small to be seen well on a modern monitor. Matplotlib, instead, plots the images so that they are always at a \"visible\" scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_first_image = mnist_train_images[0]\n",
    "mnist_first_label = mnist_train_labels[0]\n",
    "\n",
    "plt.imshow(mnist_first_image)\n",
    "plt.title(f'Label: {mnist_first_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting grayscale images (as it is the case with mnist), we should use the \"gray\" colormap for matplotlib, to avoid getting the weird purple-to-yellow color representation, which is not a faithful representation of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist_first_image, cmap=\"gray\")\n",
    "plt.title(f'Label: {mnist_first_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to normalize the data. **DIY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally construct the neural network. We can use the `Sequential` paradigm, which works by stacking up layers.\n",
    "\n",
    "**Notice that `Sequential` only works when the information flows sequentially through a NN. If there is branching, we need to use other paradigms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Sequential()\n",
    "\n",
    "mlp.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "mlp.add(Dense(32, activation='relu', input_shape=(784,)))\n",
    "mlp.add(Dense(32, activation='relu'))\n",
    "mlp.add(Dense(10, activation='softmax'))\n",
    "\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we need to **compile** the model, by specifying an optimizer and loss function. Optionally, we can also list evaluation metrics to monitor them during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp.fit(mnist_train_images, mnist_train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This refers only to the training metrics. To get the validation performance, we call `evaluate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.evaluate(mnist_validation_images, mnist_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: the method above requires to pass images and labels. At deployment time, however, we might not have labels. What can we do in this case?\n",
    "\n",
    "Experiment with it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can build a cnn to train on MNIST. This is the architecture we will reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "cnn.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "cnn.add(keras.layers.GlobalAveragePooling2D())\n",
    "cnn.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(mnist_train_images, mnist_train_labels, epochs=2)\n",
    "cnn.evaluate(mnist_validation_images, mnist_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to experiment with this model by creating our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "testimg = Image.open(\"mnist/2.jpg\")\n",
    "testimg = testimg.convert(\"L\")\n",
    "\n",
    "print(testimg.size)\n",
    "plt.imshow(testimg, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIY**\n",
    "\n",
    "* convert the image to a numpy array\n",
    "* set it up in the right format for being evaluated by the CNN (tip: batches) \n",
    "* generate a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the format of the prediction? How can we convert it to a number?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished training the model, we can save it. **TIPS**:\n",
    "\n",
    "1. Remember to save a model after training\n",
    "2. Be careful that the `save` method **overwrites by default**. If you are training multiple models, be careful about the names\n",
    "3. **Check that the folders for saving a model exist before training**. If the folder does not exist, the saving will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"mnist_cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIY**: implement a residual layer using the functional interface\n",
    "\n",
    "![](imgs/residual.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
